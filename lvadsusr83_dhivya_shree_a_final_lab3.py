# -*- coding: utf-8 -*-
"""LVADSUSR83_Dhivya_Shree_a_Final_lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ovBhbf7TKzPnposd6rCtxh-LJya0tSu
"""

#Clustering
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score

data = pd.read_csv("/content/sample_data/seeds.csv")

#Handling missing values (forward fill) and removing duplicates
data = data.fillna(data.mean())
data = data.drop_duplicates()
print(data)

#Outlier detection using IQR method
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
data = data[~outliers]

#EDA
a=data.describe()
b=data.info()
c=data.shape

# Feature scaling
scaler = StandardScaler()
scaled_features = scaler.fit_transform(data.iloc[:, :-1])

# Determine optimal number of clusters using the elbow method
sse = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_features)
    sse.append(kmeans.inertia_)

plt.plot(range(2, 11), sse, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.show()

 # model-kmeans
kmeans = KMeans(n_clusters=3, random_state=42)
data['cluster'] = kmeans.fit_predict(scaled_features)

plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', color='red')
plt.title('K-means Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

#silhouette score
silhouette_avg = silhouette_score(scaled_features, data['cluster'])
print("Silhouette Score:", silhouette_avg)