# -*- coding: utf-8 -*-
"""LVADSUSR83_Dhivya_shree_a_Final_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wsTiyTcGdVbx5zh8G2GjhLoo4Nul91Tm
"""

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import warnings
warnings.filterwarnings('ignore')
# Load the dataset
data = pd.read_csv("/content/sample_data/loan_approval.csv")  # Replace "loan_approval_dataset.csv" with the actual filename
data = data.fillna(data.mean())
data = data.drop_duplicates()
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
print("Number of outliers detected:", outliers.sum())
#EDA
a=data.describe()
b=data.shape
c=data.info()
# Encoding categorical variables
label_encoder = LabelEncoder()
data[" education"] = label_encoder.fit_transform(data[" education"])
data[' self_employed'] = label_encoder.fit_transform(data[' self_employed'])

# Splitting the dataset into features (X) and target variable (y)
X = data.drop(columns=[' loan_status', 'loan_id'])  # Dropping loan_status and loan_id
y = data[' loan_status']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)



# Model training
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train_scaled, y_train)

# Predictions on the test set
y_pred = rf_classifier.predict(X_test_scaled)

# Model evaluation
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

data.columns = data.columns.str.strip()

data.columns